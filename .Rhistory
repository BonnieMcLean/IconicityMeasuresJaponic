count(ideophone)%>%
mutate(stratum=ifelse(ideophone=="y","ideophone","prosaic"))%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size
","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))
words%>%
unique()%>%
group_by(domain)%>%
count(ideophone)%>%
mutate(stratum=ifelse(ideophone=="y","ideophone","prosaic"))
","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
words%>%
unique()%>%
group_by(domain)%>%
count(ideophone)%>%
mutate(stratum=ifelse(ideophone=="y","ideophone","prosaic"))%>%
mutate(domain=fct_relevel(as.factor(domain),c("sound","action","shape & size
","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))
words%>%
unique()%>%
group_by(domain)%>%
count(ideophone)%>%
mutate(stratum=ifelse(ideophone=="y","ideophone","prosaic"))->graph
graph$domain
View(graph)
levels(graph$domain)
graph$domain <- as.factor(graph$domain)
levels(graph$domain)
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size
","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))
levels(graph$domain)
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(c("grey","black"))
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(c("gray","black"))
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual("gray","black")
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual("grey","black")
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("grey","black"))
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("black","grey"))
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("grey","black"))
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))
dat <- read_csv("https://raw.githubusercontent.com/BonnieMcLean/JaponicSensoryLex/main/dat.csv")
info <-
words <- read_csv("responses-guessingwords.csv")%>%
select(identifier)%>%
mutate(identifier=str_replace_all(identifier,"FUZZY","CLEAR"))%>%
unique()
cognates <- read_csv("cognatecodes.csv")%>%
mutate(identifier=paste(test_form,eng_trans,sep="_"))%>%select(cognate,identifier)
words <- words%>%left_join(cognates,by="identifier")
View(words)
cognates <- read_csv("cognatecodes.csv")%>%
mutate(identifier=paste(test_form,eng_trans,sep="_"))%>%select(cognate,identifier,location)
cognates <- read_csv("cognatecodes.csv")%>%
mutate(identifier=paste(test_form,eng_trans,sep="_"))%>%select(cognate,identifier,locations)
words <- words%>%left_join(cognates,by="identifier")
words <- read_csv("responses-guessingwords.csv")%>%
select(identifier)%>%
mutate(identifier=str_replace_all(identifier,"FUZZY","CLEAR"))%>%
unique()
cognates <- read_csv("cognatecodes.csv")%>%
mutate(identifier=paste(test_form,eng_trans,sep="_"))%>%select(cognate,identifier,locations)
words <- words%>%left_join(cognates,by="identifier")
words <- read_csv("responses-guessingwords.csv")%>%
select(form,identifier)%>%
mutate(identifier=str_replace_all(identifier,"FUZZY","CLEAR"))%>%
unique()
cognates <- read_csv("cognatecodes.csv")%>%
mutate(identifier=paste(test_form,eng_trans,sep="_"))%>%select(cognate,identifier,varieties)
words <- words%>%left_join(cognates,by="identifier")
words <- words%>%left_join(cognates,by="identifier")%>%
separate_rows(varieties,sep=", ")
colnames(words)
words <- words%>%left_join(cognates,by="identifier")
words <- read_csv("responses-guessingwords.csv")%>%
select(form,identifier)%>%
mutate(identifier=str_replace_all(identifier,"FUZZY","CLEAR"))%>%
unique()
cognates <- read_csv("cognatecodes.csv")%>%
mutate(identifier=paste(test_form,eng_trans,sep="_"))%>%select(cognate,identifier,varieties)
words <- words%>%left_join(cognates,by="identifier")%>%
separate_rows(varieties,sep=", ")
View(dat)
dat <- read_csv("https://raw.githubusercontent.com/BonnieMcLean/JaponicSensoryLex/main/dat.csv")
dat <- read_csv("https://raw.githubusercontent.com/BonnieMcLean/JaponicSensoryLex/main/dat.csv")
words <- read_csv("responses-guessingwords.csv")%>%
select(form,identifier)%>%
mutate(identifier=str_replace_all(identifier,"FUZZY","CLEAR"))%>%
unique()
cognates <- read_csv("cognatecodes.csv")%>%
mutate(identifier=paste(test_form,eng_trans,sep="_"))%>%select(cognate,identifier)
words <- words%>%left_join(cognates,by="identifier")
words <- words%>%left_join(cognates,by="identifier")%>%
mutate(concept=str_split(identifier)[[1]][2])
words <- words%>%left_join(cognates,by="identifier")%>%
mutate(concept=str_split(identifier,sep="_")[[1]][2])
dat <- read_csv("https://raw.githubusercontent.com/BonnieMcLean/JaponicSensoryLex/main/dat.csv")
words <- read_csv("responses-guessingwords.csv")%>%
select(form,identifier)%>%
mutate(identifier=str_replace_all(identifier,"FUZZY","CLEAR"))%>%
unique()
cognates <- read_csv("cognatecodes.csv")%>%
mutate(identifier=paste(test_form,eng_trans,sep="_"))%>%select(cognate,identifier)
words <- words%>%left_join(cognates,by="identifier")%>%
mutate(concept=str_split(identifier,"_")[[1]][2])
dat <- read_csv("https://raw.githubusercontent.com/BonnieMcLean/JaponicSensoryLex/main/dat.csv")
words <- read_csv("responses-guessingwords.csv")%>%
select(form,identifier)%>%
mutate(identifier=str_replace_all(identifier,"FUZZY","CLEAR"))%>%
unique()
cognates <- read_csv("cognatecodes.csv")%>%
mutate(identifier=paste(test_form,eng_trans,sep="_"))%>%select(cognate,identifier)
words <- words%>%left_join(cognates,by="identifier")%>%
rowwise()%>%
mutate(concept=str_split(identifier,"_")[[1]][2])
dat <- read_csv("https://raw.githubusercontent.com/BonnieMcLean/JaponicSensoryLex/main/dat.csv")%>%
select(Concept,Location,Form,CognateCode)%>%
mutate(concept=str_split(Concept,"-")[[1]][1])
dat <- read_csv("https://raw.githubusercontent.com/BonnieMcLean/JaponicSensoryLex/main/dat.csv")%>%
select(Concept,Location,Form,CognateCode)%>%
rowwise()%>%
mutate(concept=str_split(Concept,"-")[[1]][1])
dat <- read_csv("https://raw.githubusercontent.com/BonnieMcLean/JaponicSensoryLex/main/dat.csv")%>%
select(Concept,Location,Form,CognateCode)%>%
rowwise()%>%
mutate(concept=str_split(Concept,"-")[[1]][1])
words <- read_csv("responses-guessingwords.csv")%>%
select(form,identifier)%>%
mutate(identifier=str_replace_all(identifier,"FUZZY","CLEAR"))%>%
unique()
cognates <- read_csv("cognatecodes.csv")%>%
mutate(identifier=paste(test_form,eng_trans,sep="_"))%>%select(cognate,identifier)
words <- words%>%left_join(cognates,by="identifier")%>%
rowwise()%>%
mutate(concept=str_split(identifier,"_")[[1]][2])%>%unique()
ratings <- read_csv("responses-ratings.csv")
ratings%>%
select(experiment,identifier)%>%
unique()
ratings%>%
select(experiment,identifier)%>%
unique()%>%
sum(experiment)
ratings%>%
select(experiment,identifier)%>%
unique()%>%
group_by(experiment)%>%
count()
# Chunk 1: global_options
knitr::opts_chunk$set(fig.width=8, fig.height=6, fig.path='figures_md/',
echo=TRUE, warning=FALSE, message=FALSE)
# Chunk 2: preliminaries
# Packages
library(tidyverse)
library(readxl)
library(plyr)
library(ggthemes)
library(gghalves)
library(car)
library(emmeans)
library(plotly)
library(ggpubr)
library(viridis)
# useful functions
`%notin%` <- function(x,y) !(x %in% y)
mean.na <- function(x) mean(x, na.rm = T)
sd.na <- function(x) sd(x, na.rm = T)
# Chunk 3
# load dataframe with all ratings
read.csv("data\\ideophones_rated_uncorr.csv",header=TRUE,na.strings=c("", "NA"),sep=";",check.names=FALSE) -> d.uncorr
# to long format
d.uncorr <- gather(d.uncorr, item, rating, 6:245)
d.uncorr <- d.uncorr[,c(1,6,7)]
colnames(d.uncorr) <- c("rater","item","rating")
#remove empty cells
d.uncorr <- subset(d.uncorr, !is.na(d.uncorr[,"rating"]))
#change ratings to numeric values with decimals
as.numeric(sub(",", ".", d.uncorr$rating, fixed = TRUE)) -> d.uncorr$rating
# check for inconsistent raters with person-total correlation based on Motamedi et al. (2019)
ptc <- d.uncorr[,c("item","rater","rating")]
personTotalCorrelationCorrected <- function(ptc)
{
require(tidyverse)
ptc %>%
dplyr::rename(raterFocal = rater,
ratingFocal = rating) %>%
full_join(ptc, by='item') %>%
filter(rater!=raterFocal) %>%
group_by(item, raterFocal, ratingFocal) %>%
summarise(ratingsOthers = mean(rating, na.rm=TRUE)) %>%
base::split(.$raterFocal) %>%
map(~cor(.$ratingFocal, .$ratingsOthers,
use="pairwise.complete.obs")) %>%
as.data.frame %>%
gather %>%
dplyr::rename(rater = key, perTotCor = value)
}
View(personTotalCorrelationCorrected(ptc))
#plot person-total correlations
ptc %>%
select(item, rater, rating) %>%
personTotalCorrelationCorrected %>%
ggplot(aes(x=perTotCor)) +
geom_density() +
geom_histogram(stat="bin",
alpha=0.4,
aes(y=..density..),
binwidth=0.1) +
labs(x="Person-total correlation")
ggsave("figures\\rating_PerTotCorr.png",height=5,width=7.5)
# Chunk 4
# load corrected data
d <- read_xlsx("data\\ideophones_rated.xlsx")
d.means <- read_xlsx("data\\ideophones_rated_means.xlsx")
# get means and standard deviations across all ideophones and for each language and category
mean(d$rating)
# 2.948339
sd(d$rating)
# 1.297106
sumcat <- ddply(d,~category,summarise,mean=mean(rating),sd=sd(rating))
sumlang <- ddply(d,~language,summarise,mean=mean(rating),sd=sd(rating))
# Chunk 5
#create copy of data including the category "Other"
d.other <- read_xlsx("data\\ideophones_rated.xlsx")
d.m.other <- read_xlsx("data\\ideophones_rated_means.xlsx")
#remove category "Other" from d and d.means
d <- d[!grepl("Other",d$category),]
d.means <- d.means[!grepl("Other",d.means$category),]
# make new summary for language (without the Japanese "other" ideophones)
sumlang2 <- ddply(d,~language,summarise,mean=mean(rating),sd=sd(rating))
#convert some columns to factors
cols <- c("category","language","study")
d[cols] <- lapply(d[cols], factor)
d.means[cols] <- lapply(d.means[cols], factor)
#combined boxplot and scatterplot by category
ggplot(d.means, aes(x=reorder(category,-rating),y=rating,color=category)) +
theme_tufte(base_size=16) +
geom_half_boxplot(aes(middle=mean(rating)),show.legend=F) +
geom_half_point(show.legend=F) +
scale_colour_viridis_d(option="D",alpha=0.8) +
xlab("category") + scale_x_discrete(labels = c("Sound","Motion","Shape",
"Texture","Colour/Visual"))
ggsave("figures\\rating_category.png",height=5,width=7.5)
#same, but by language
ggplot(d.means, aes(x=reorder(language,-rating),y=rating,color=language)) +
theme_tufte(base_size=16) +
geom_half_boxplot(aes(middle=mean(rating)),show.legend=F) +
geom_half_point(show.legend=F) +
scale_colour_viridis_d(option="D",alpha=0.8) +
xlab("category")
ggsave("figures\\rating_language.png",height=5,width=7.5)
# Packages
library(tidyverse)
library(readxl)
library(plyr)
library(ggthemes)
library(gghalves)
library(car)
library(emmeans)
library(plotly)
library(ggpubr)
library(viridis)
# useful functions
`%notin%` <- function(x,y) !(x %in% y)
mean.na <- function(x) mean(x, na.rm = T)
sd.na <- function(x) sd(x, na.rm = T)
# load dataframe with all ratings
read.csv("data\\ideophones_rated_uncorr.csv",header=TRUE,na.strings=c("", "NA"),sep=";",check.names=FALSE) -> d.uncorr
# to long format
d.uncorr <- gather(d.uncorr, item, rating, 6:245)
d.uncorr <- d.uncorr[,c(1,6,7)]
colnames(d.uncorr) <- c("rater","item","rating")
#remove empty cells
d.uncorr <- subset(d.uncorr, !is.na(d.uncorr[,"rating"]))
#change ratings to numeric values with decimals
as.numeric(sub(",", ".", d.uncorr$rating, fixed = TRUE)) -> d.uncorr$rating
# check for inconsistent raters with person-total correlation based on Motamedi et al. (2019)
ptc <- d.uncorr[,c("item","rater","rating")]
personTotalCorrelationCorrected <- function(ptc)
{
require(tidyverse)
ptc %>%
dplyr::rename(raterFocal = rater,
ratingFocal = rating) %>%
full_join(ptc, by='item') %>%
filter(rater!=raterFocal) %>%
group_by(item, raterFocal, ratingFocal) %>%
summarise(ratingsOthers = mean(rating, na.rm=TRUE)) %>%
base::split(.$raterFocal) %>%
map(~cor(.$ratingFocal, .$ratingsOthers,
use="pairwise.complete.obs")) %>%
as.data.frame %>%
gather %>%
dplyr::rename(rater = key, perTotCor = value)
}
View(personTotalCorrelationCorrected(ptc))
#plot person-total correlations
ptc %>%
select(item, rater, rating) %>%
personTotalCorrelationCorrected %>%
ggplot(aes(x=perTotCor)) +
geom_density() +
geom_histogram(stat="bin",
alpha=0.4,
aes(y=..density..),
binwidth=0.1) +
labs(x="Person-total correlation")
ggsave("figures\\rating_PerTotCorr.png",height=5,width=7.5)
# load corrected data
d <- read_xlsx("data\\ideophones_rated.xlsx")
d.means <- read_xlsx("data\\ideophones_rated_means.xlsx")
# get means and standard deviations across all ideophones and for each language and category
mean(d$rating)
# 2.948339
sd(d$rating)
# 1.297106
sumcat <- ddply(d,~category,summarise,mean=mean(rating),sd=sd(rating))
sumlang <- ddply(d,~language,summarise,mean=mean(rating),sd=sd(rating))
# load corrected data
d <- read_xlsx("data\\ideophones_rated.xlsx")
setwd("C:/Users/bonmc643/triangulating_iconicity")
# load corrected data
d <- read_xlsx("data\\ideophones_rated.xlsx")
d.means <- read_xlsx("data\\ideophones_rated_means.xlsx")
# get means and standard deviations across all ideophones and for each language and category
mean(d$rating)
# 2.948339
sd(d$rating)
# 1.297106
sumcat <- ddply(d,~category,summarise,mean=mean(rating),sd=sd(rating))
sumlang <- ddply(d,~language,summarise,mean=mean(rating),sd=sd(rating))
#create copy of data including the category "Other"
d.other <- read_xlsx("data\\ideophones_rated.xlsx")
d.m.other <- read_xlsx("data\\ideophones_rated_means.xlsx")
#remove category "Other" from d and d.means
d <- d[!grepl("Other",d$category),]
d.means <- d.means[!grepl("Other",d.means$category),]
# make new summary for language (without the Japanese "other" ideophones)
sumlang2 <- ddply(d,~language,summarise,mean=mean(rating),sd=sd(rating))
#convert some columns to factors
cols <- c("category","language","study")
d[cols] <- lapply(d[cols], factor)
d.means[cols] <- lapply(d.means[cols], factor)
#combined boxplot and scatterplot by category
ggplot(d.means, aes(x=reorder(category,-rating),y=rating,color=category)) +
theme_tufte(base_size=16) +
geom_half_boxplot(aes(middle=mean(rating)),show.legend=F) +
geom_half_point(show.legend=F) +
scale_colour_viridis_d(option="D",alpha=0.8) +
xlab("category") + scale_x_discrete(labels = c("Sound","Motion","Shape",
"Texture","Colour/Visual"))
ggsave("figures\\rating_category.png",height=5,width=7.5)
#same, but by language
ggplot(d.means, aes(x=reorder(language,-rating),y=rating,color=language)) +
theme_tufte(base_size=16) +
geom_half_boxplot(aes(middle=mean(rating)),show.legend=F) +
geom_half_point(show.legend=F) +
scale_colour_viridis_d(option="D",alpha=0.8) +
xlab("category")
ggsave("figures\\rating_language.png",height=5,width=7.5)
#same, but by language
ggplot(d.means, aes(x=reorder(language,-rating),y=rating,color=language)) +
theme_tufte(base_size=16) +
geom_half_boxplot(aes(middle=mean(rating)),show.legend=F) +
geom_half_point(show.legend=F) +
scale_colour_viridis_d(option="D",alpha=0.8) +
xlab("category")
#combined boxplot and scatterplot by category
ggplot(d.means, aes(x=reorder(category,-rating),y=rating,color=category)) +
theme_tufte(base_size=16) +
geom_half_boxplot(aes(middle=mean(rating)),show.legend=F) +
geom_half_point(show.legend=F) +
scale_colour_viridis_d(option="D",alpha=0.8) +
xlab("category") + scale_x_discrete(labels = c("Sound","Motion","Shape",
"Texture","Colour/Visual"))
everything%>%
ggplot(aes(x=method,y=score))+geom_half_violin()+geom_half_point()+theme_classic()+labs(x="Method",y="Guessing accuracy / Iconicity rating")+scale_x_discrete(limits=c("guesses between translations","guesses between words","iconicity ratings","native iconicity ratings\n(Thompson et al. 2020)"))+theme(axis.text.x = element_text(angle=15,vjust=0.6))+scale_y_continuous(breaks=c(0,1))
guesses_words%>%
group_by(identifier)%>%
mutate(score=sum(answer=="correct")/sum(answer=="correct"|answer=="incorrect"))%>%
select(identifier,score)%>%
unique()%>%
mutate(method="guesses between words")->oppres
setwd("C:/Users/bonmc643/IconicityMeasuresJaponic")
guesses_words%>%
group_by(identifier)%>%
mutate(score=sum(answer=="correct")/sum(answer=="correct"|answer=="incorrect"))%>%
select(identifier,score)%>%
unique()%>%
mutate(method="guesses between words")->oppres
library(tidyverse)
library(kableExtra)
library(bookdown)
library(report)
library(lmerTest)
library(plotly)
library(corrr)
library(boot)
library(zeallot)
library(pander)
library(sjPlot)
library(ggeffects)
library(gridExtra)
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message = FALSE)
# semantic domains of concepts, plus numbers of ideophones and non-ideophones
concepts <- read_tsv("https://raw.githubusercontent.com/BonnieMcLean/JaponicSensoryLex/main/concepts.tsv")%>%
rowwise()%>%
mutate(concept=str_split(concept,"-")[[1]][1])%>%
select(concept,domain)
words <- read_csv("responses-guessingwords.csv")%>%
select(form,identifier)%>%
mutate(identifier=str_replace_all(identifier,"FUZZY","CLEAR"))%>%
rowwise()%>%
mutate(concept=str_split(identifier,"_")[[1]][2])%>%
unique()%>%
left_join(concepts,by="concept")
words <- read_csv("ideophone_list.csv")%>%
select(form,ideophone)%>%
right_join(words,by="form")
# plus the practise and control items which arent in the Japonic sensory lexicon
words$domain[words$form == "yoroyoro"] <- "action"
words$domain[words$form == "fuwafuwa"] <- "texture"
words$domain[words$form == "hisohiso"] <- "sound"
words$domain[words$form == "pyoNpyoN"] <- "action"
words$domain[words$form == "zyiNzyiN"] <- "pain"
words$domain[words$form == "gaNgaN"] <- "pain"
words%>%
unique()%>%
group_by(domain)%>%
count(ideophone)%>%
mutate(stratum=ifelse(ideophone=="y","ideophone","prosaic"))->graph
# semantic domains of concepts, plus numbers of ideophones and non-ideophones
concepts <- read_tsv("https://raw.githubusercontent.com/BonnieMcLean/JaponicSensoryLex/main/concepts.tsv")%>%
rowwise()%>%
mutate(concept=str_split(concept,"-")[[1]][1])%>%
select(concept,domain)
words <- read_csv("responses-guessingwords.csv")%>%
select(form,identifier)%>%
mutate(identifier=str_replace_all(identifier,"FUZZY","CLEAR"))%>%
rowwise()%>%
mutate(concept=str_split(identifier,"_")[[1]][2])%>%
unique()%>%
left_join(concepts,by="concept")
words <- read_csv("ideophone_list.csv")%>%
select(form,ideophone)%>%
right_join(words,by="form")
# plus the practise and control items which arent in the Japonic sensory lexicon
words$domain[words$form == "yoroyoro"] <- "action"
words$domain[words$form == "fuwafuwa"] <- "texture"
words$domain[words$form == "hisohiso"] <- "sound"
words$domain[words$form == "pyoNpyoN"] <- "action"
words$domain[words$form == "zyiNzyiN"] <- "pain"
words$domain[words$form == "gaNgaN"] <- "pain"
words%>%
unique()%>%
group_by(domain)%>%
count(ideophone)%>%
mutate(stratum=ifelse(ideophone=="y","ideophone","prosaic"))->graph
# semantic domains of concepts, plus numbers of ideophones and non-ideophones
concepts <- read_tsv("https://raw.githubusercontent.com/BonnieMcLean/JaponicSensoryLex/main/concepts.tsv")%>%
rowwise()%>%
mutate(concept=str_split(concept,"-")[[1]][1])%>%
select(concept,domain)
words <- read_csv("responses-guessingwords.csv")%>%
select(form,identifier)%>%
mutate(identifier=str_replace_all(identifier,"FUZZY","CLEAR"))%>%
rowwise()%>%
mutate(concept=str_split(identifier,"_")[[1]][2])%>%
unique()%>%
left_join(concepts,by="concept")
words <- read_csv("ideophone_list.csv")%>%
select(form,ideophone)%>%
right_join(words,by="form")
# plus the practise and control items which arent in the Japonic sensory lexicon
words$domain[words$form == "yoroyoro"] <- "action"
words$domain[words$form == "fuwafuwa"] <- "texture"
words$domain[words$form == "hisohiso"] <- "sound"
words$domain[words$form == "pyoNpyoN"] <- "action"
words$domain[words$form == "zyiNzyiN"] <- "pain"
words$domain[words$form == "gaNgaN"] <- "pain"
words%>%
unique()%>%
group_by(domain)%>%
count(ideophone)%>%
mutate(stratum=ifelse(ideophone=="y","ideophone","prosaic"))->graph
words%>%
unique()%>%
group_by(domain)
words%>%
unique()%>%
group_by(domain)%>%
count(ideophone)%>%
mutate(stratum=ifelse(ideophone=="y","ideophone","prosaic"))->graph
