distribution_controlratings <- ggplot(data=examine_participants,aes(x=mean_rating))+geom_histogram()+scale_x_continuous(n.breaks=20)
# person-total correlations
participants <- unique(ratings$prolificID)
correlations <- c()
for(p in participants){
# get the mean ratings of everyone else
othersratings <- ratings%>%filter(prolificID!=p)%>%
group_by(identifier)%>%
mutate(mean_rating=mean(rating))%>%
select(identifier,mean_rating)%>%
unique()
# get the participants ratings
participantratings <- ratings%>%filter(prolificID==p)%>%select(identifier,rating)
# join them and compute the correlation
compare <- left_join(participantratings,othersratings,by="identifier")
corr <- cor(compare$rating,compare$mean_rating,use="pairwise.complete.obs")
correlations <- c(correlations,corr)
}
persontotals <- data.frame(participants,correlations)%>%rename(prolificID=participants,pt_corr=correlations)
persontotal_dist <- ggplot(data=persontotals,aes(x=pt_corr))+geom_histogram()+scale_x_continuous(n.breaks=8)
examine_participants <- left_join(examine_participants,persontotals,by="prolificID")
exclude_participants <- c("60ccf2e72ef0587d5cc4e2cd","60ce01c71f2eaca4a5050416","5fd64479bf40a251701159d6","5c8026f0f399120012fa4238","5ca73fe6bcdcc2001291822d")
ratings <- ratings%>%
filter(!(prolificID %in% exclude_participants))
ratings%>%
select(identifier,prolificID)%>%
unique()%>%
group_by(identifier)%>%
count()%>%
filter(n<200)->no_ratings
#median(no_ratings$n)
guesses_words%>%
select(identifier,prolificID)%>%
unique()%>%
group_by(identifier)%>%
count()%>%
filter(n<200)->guess1
# median(guess1$n)
guesses_trans%>%
mutate(identifier=paste(word,concept))%>%
select(identifier,Prolific.ID)%>%
unique()%>%
group_by(identifier)%>%
count()%>%
filter(n<200)->guess2
#median(guess2$n)
knitr::include_graphics("images/guessingtransdemo.PNG")
guesses_trans%>%
mutate(word_spec=paste(word,concept,sep="_"))->guesses_trans
guesses_trans%>%
filter(word_spec=="piiN_LONG"|word_spec=="hakkiri_CLEAR-HEADED")%>%
filter(!(grepl("SHARP",answer_sen)))%>%
select(answer_sen,foil_sen,answer)%>%
group_by(answer_sen,foil_sen)%>%
count(answer)%>%
pivot_wider(names_from=answer,values_from=n, values_fill=0)%>%
knitr::kable(col.names = c("Answer sentence", "Foil sentence","correct","incorrect"),caption="Effect of different foils and translations on guessing results for hakkiri 'CLEAR HEADED' and piiN 'LONG'")%>%
kable_styling()
knitr::include_graphics("images/guessingwords.PNG")
knitr::include_graphics("images/guessingwordsspec.PNG")
knitr::include_graphics("images/vowels.PNG")
knitr::include_graphics("images/ratingdemo.PNG")
# for guessing between translations
words<-unique(guesses_trans$word_spec)
# see whether the responses differed significantly depending on the answer sentence given
n=0
doubly_tested_words <- c()
weird_words<-c()
for(w in words){
d<-subset(guesses_trans,word_spec==w)
t<-table(d$answer_sen,d$answer)
# not all words were tested with more than one translation as for some concepts there was only one English word for the concept
if (nrow(t)>1){
doubly_tested_words <- c(doubly_tested_words,w)
n=n+1
p_val<-fisher.test(t)$p
if (p_val<0.05){
weird_words<-c(weird_words,w)}
}
}
# see whether the responses different signficantly depending on the foil sentence given
for(w in words){
d<-subset(guesses_trans,word_spec==w)
t<-table(d$foil_sen,d$answer)
if (nrow(t)>1){
doubly_tested_words <- c(doubly_tested_words,w)
n=n+1
p_val<-fisher.test(t)$p
if (p_val<0.05){
weird_words<-c(weird_words,w)}
}
}
weird_res_trans <- length(unique(weird_words))/length(unique(doubly_tested_words))
# for guessing between words
words<-unique(guesses_words$identifier)
# see whether the responses differed significantly depending on the answer sentence given
n=0
doubly_tested_words <- c()
weird_words<-c()
for(w in words){
d<-subset(guesses_words,identifier==w)
t<-table(d$trans,d$answer)
if (nrow(t)>1&ncol(t)>1){
doubly_tested_words <- c(doubly_tested_words,w)
n=n+1
p_val<-fisher.test(t)$p
if (p_val<0.05){
weird_words<-c(weird_words,w)}
}
}
# see whether the responses different signficantly depending on the foil sentence given
for(w in words){
d<-subset(guesses_words,identifier==w)
t<-table(d$foil,d$answer)
if (nrow(t)>1 & ncol(t)>1){
doubly_tested_words <- c(doubly_tested_words,w)
n=n+1
p_val<-fisher.test(t)$p
if (p_val<0.05){
weird_words<-c(weird_words,w)}
}
}
weird_res_words <- length(unique(weird_words))/length(unique(doubly_tested_words))
# for the ratings we are using anovas which are not as robust to small amounts of data as the fisher test
# therefore I only looked at data where we had at least ten ratings per translation
ratings%>%
select(identifier,trans,rating)%>%
group_by(identifier)%>%
add_count(trans)%>%
filter(n>=10)->data
# then within this, we need to get the data where we have at least two translations per word
data%>%
select(identifier,trans)%>%
unique()%>%
group_by(identifier)%>%
mutate(count=n())%>%
arrange(identifier)%>%
filter(count>1)%>%
pull(identifier) -> test
data <- subset(data,identifier %in% test)
words <- unique(data$identifier)
weird_res <- c()
for(w in words){
d <- subset(data,identifier==w)
n_trans <- length(unique(d$trans))
if(n_trans==2){
t <- t.test(d$rating~d$trans)
p <- t$p.value
}
else{
t <- summary(aov(d$rating~d$trans))
p <- t[[1]][[5]][1]
}
if(p<0.05){weird_res <- c(weird_res,w)}
}
weird_res_ratings <- length(weird_res)/length(words)
# we used this binomial test to figure out how many correct guesses (out of 30) were needed to have a result significantly different from chance--it's 21
#binom.test(21,30,p=.5)
randomfoils <- read_csv("responses-randomfoils.csv")
randomfoils%>%
group_by(identifier)%>%
mutate(score=sum(result=="correct")/sum(result=="correct"|result=="incorrect"))%>%
select(form,score)%>%unique()->randomres
# fix up some naming differences
words <- randomres$identifier
words <- replace(words,words=="zoNzoN_SHIVERING","zoNzoN_(SPINE) TINGLING")
words <- replace(words,words=="geNki_LIVELY","geNki_LIVELY (ENERGETIC)")
guesses_words%>%
filter(identifier %in% words|form=="zyiNzyiN")%>%
group_by(identifier)%>%
mutate(score=sum(answer=="correct")/sum(answer=="correct"|answer=="incorrect"))%>%
ungroup()%>%
select(form,score)%>%unique()->oppres
comparison <- left_join(randomres%>%select(-identifier),oppres,by="form")%>%
rename(random_foils=score.x,opp_foils=score.y)%>%unique()
comparison%>%
rename(`random foils`=random_foils,`opposite foils`=opp_foils)%>%
pivot_longer(c("random foils","opposite foils"),names_to="design",values_to="accuracy")%>%
mutate(`guessing accuracy`=ifelse(accuracy>2/3,"significantly above chance","at chance"))%>%
ungroup()%>%
select(design,`guessing accuracy`)%>%
group_by(design)%>%
count(`guessing accuracy`)%>%
ggplot(aes(x=design,y=n,fill=`guessing accuracy`))+geom_col()+theme_classic()+labs(x="Design",y="Number of words")+scale_fill_manual(values=c("#CCCCCC","#000000"))
comparison%>%
rename(`random foils`=random_foils,`opposite foils`=opp_foils)%>%
pivot_longer(c("random foils","opposite foils"),names_to="design",values_to="accuracy")%>%
mutate(`above chance`=ifelse(accuracy>2/3,"y","n"))->comparison
#table(comparison$design,comparison$`above chance`)
#chisq.test(table(comparison$design,comparison$`above chance`))
guesses_words%>%
group_by(identifier)%>%
mutate(score=sum(answer=="correct")/sum(answer=="correct"|answer=="incorrect"))%>%
select(identifier,score)%>%
unique()%>%
mutate(method="guesses between words")->oppres
guesses_trans%>%
group_by(word_spec)%>%
mutate(score=sum(answer=="correct")/sum(answer=="correct"|answer=="incorrect"))%>%
select(identifier=word_spec,score)%>%
unique()%>%
mutate(method="guesses between translations")->transres
ratings%>%
group_by(identifier)%>%
mutate(mean_rating=mean(rating))%>%
mutate(norm_rating=mean_rating/6)%>%
select(identifier,score=norm_rating)%>%
unique()%>%
mutate(method="iconicity ratings")->ratingres
# also compare with ratings from native speakers
japratings <- read_csv("https://osf.io/2praq/download")
japratings%>%
filter(stratum=="Yamato"|stratum=="Ideophonic")%>%
filter(category=="verb"|category=="adverb"|category=="adjective"|category=="ideophone")%>%
filter(rating>=0)%>%
group_by(wordCode)%>%
mutate(iconicityM=mean(rating))%>%
ungroup()%>%
mutate(task="Thompson et al. 2020")%>%
mutate(ideophone=ifelse(category=="ideophone","y","n"))%>%
select(wordCode,iconicityM,rating,task,ideophone)->thompson
thompson%>%
select(-rating,-ideophone)%>%
unique()%>%
mutate(score=iconicityM/5)%>%
mutate(method="native iconicity ratings\n(Thompson et al. 2020)")%>%
select(identifier=wordCode,score,method)->japres
everything <- rbind(oppres,transres,ratingres,japres)
#everything$method <- as.factor(everything$method)
#levels(everything$method) <- c("guessing between words (n=131)","guessing between translations (n=77)","iconicity ratings (n=118)")
everything%>%
ggplot(aes(x=method,y=score))+geom_half_violin()+geom_half_point()+theme_classic()+labs(x="Method",y="Guessing accuracy / Iconicity rating")+scale_x_discrete(limits=c("guesses between translations","guesses between words","iconicity ratings","native iconicity ratings\n(Thompson et al. 2020)"))+theme(axis.text.x = element_text(angle=15,vjust=0.6))+scale_y_continuous(breaks=c(0,1))
library(gghalves)
everything%>%
ggplot(aes(x=method,y=score))+geom_half_violin()+geom_half_point()+theme_classic()+labs(x="Method",y="Guessing accuracy / Iconicity rating")+scale_x_discrete(limits=c("guesses between translations","guesses between words","iconicity ratings","native iconicity ratings\n(Thompson et al. 2020)"))+theme(axis.text.x = element_text(angle=15,vjust=0.6))+scale_y_continuous(breaks=c(0,1))
everything%>%
ggplot(aes(x=method,y=score))+geom_half_violin()+geom_half_point()+theme_classic()+labs(x="Method",y="Guessing accuracy / Iconicity rating")+scale_x_discrete(limits=c("guesses between translations","guesses between words","iconicity ratings","native iconicity ratings\n(Thompson et al. 2020)"))+theme(axis.text.x = element_text(angle=15,vjust=0.6))
everything%>%
ggplot(aes(x=method,y=score))+geom_half_violin()+geom_half_point()+theme_classic()+labs(x="Method",y="Guessing accuracy / Iconicity rating")+scale_x_discrete(limits=c("guesses between translations","guesses between words","iconicity ratings","native iconicity ratings\n(Thompson et al. 2020)"))+theme(axis.text.x = element_text(angle=15,vjust=0.6))+scale_y_continuous(breaks=c(0,1))
everything%>%
ggplot(aes(x=method,y=score))+geom_half_violin()+geom_half_point()+theme_classic()+labs(x="Method",y="Guessing accuracy / Iconicity rating")+scale_x_discrete(limits=c("guesses between translations","guesses between words","iconicity ratings","native iconicity ratings\n(Thompson et al. 2020)"))+theme(axis.text.x = element_text(angle=15,vjust=0.6))+ylim(0,1)
# get info on ideophones
words <- read_csv("ideophone_list.csv")
words%>%
select(form,ideophone)->info
# combine data
comparison <- rbind(oppres,ratingres)
comparison%>%
mutate(method=str_replace(method,"guess.*","guesses"))%>%
mutate(method=str_replace(method,".* ratings.*","ratings"))%>%
group_by(method)%>%
mutate(z_score=(score-mean(score))/sd(score))%>%
# only look at words where you have both ratings and guesses
filter(identifier %in% intersect(oppres$identifier,ratingres$identifier))%>%
rowwise()%>%
mutate(form=str_split(identifier,"_")[[1]][1])%>%
left_join(info)%>%
unique()%>%
select(identifier,ideophone,method,z_score,score)->comparison_dat
comparison_dat%>%
filter(method=="ratings")%>%
mutate(mean_rating=6*score)%>%
mutate(word_type=ifelse(ideophone=="y","ideophones","non-ideophones"))%>%
ggplot(aes(x=word_type,y=mean_rating))+geom_violin()+theme_classic()+ylim(0,6)+labs(x="Word type",y="Mean rating")->plot1
comparison_dat%>%
filter(method=="guesses")%>%
mutate(word_type=ifelse(ideophone=="y","ideophones","non-ideophones"))%>%
ggplot(aes(x=word_type,y=score))+geom_half_violin()+geom_half_point()+theme_classic()+ylim(0,1)+labs(x="Word type",y="Guessing accuracy")->plot2
#comparison_dat%>%
# filter(method=="guesses between translations")%>%
#  filter(score>1/3)%>%
#  ggplot(aes(x=ideophone,y=score))+geom_violin()+theme_classic()+ylim(0,1)->plot3
grid.arrange(plot1,plot2,ncol=2)
comparison_dat%>%
filter(method=="ratings")%>%
mutate(mean_rating=6*score)%>%
mutate(word_type=ifelse(ideophone=="y","ideophones","non-ideophones"))%>%
ggplot(aes(x=word_type,y=mean_rating))+geom_half_violin()+geom_half_point()+theme_classic()+ylim(0,6)+labs(x="Word type",y="Mean rating")->plot1
#comparison_dat%>%
# filter(method=="guesses between translations")%>%
#  filter(score>1/3)%>%
#  ggplot(aes(x=ideophone,y=score))+geom_violin()+theme_classic()+ylim(0,1)->plot3
grid.arrange(plot1,plot2,ncol=2)
# get info on ideophones
words <- read_csv("ideophone_list.csv")
words%>%
select(form,ideophone)->info
# combine data
comparison <- rbind(oppres,ratingres)
comparison%>%
mutate(method=str_replace(method,"guess.*","guesses"))%>%
mutate(method=str_replace(method,".* ratings.*","ratings"))%>%
group_by(method)%>%
mutate(z_score=(score-mean(score))/sd(score))%>%
# only look at words where you have both ratings and guesses
filter(identifier %in% intersect(oppres$identifier,ratingres$identifier))%>%
rowwise()%>%
mutate(form=str_split(identifier,"_")[[1]][1])%>%
left_join(info)%>%
unique()%>%
select(identifier,ideophone,method,z_score,score)->comparison_dat
comparison_dat%>%
filter(method=="ratings")%>%
mutate(mean_rating=6*score)%>%
mutate(word_type=ifelse(ideophone=="y","ideophone","prosaic"))%>%
ggplot(aes(x=word_type,y=mean_rating))+geom_half_violin()+geom_half_point()+theme_classic()+ylim(0,6)+labs(x="Lexical stratum",y="Mean rating")->plot1
comparison_dat%>%
filter(method=="guesses")%>%
mutate(word_type=ifelse(ideophone=="y","ideophone","prosaic"))%>%
ggplot(aes(x=word_type,y=score))+geom_half_violin()+geom_half_point()+theme_classic()+ylim(0,1)+labs(x="Lexical stratum",y="Guessing accuracy")->plot2
#comparison_dat%>%
# filter(method=="guesses between translations")%>%
#  filter(score>1/3)%>%
#  ggplot(aes(x=ideophone,y=score))+geom_violin()+theme_classic()+ylim(0,1)->plot3
grid.arrange(plot1,plot2,ncol=2)
comparison_dat%>%
select(-score)%>%
pivot_wider(names_from = "method",values_from="z_score")->comparison_dat
comparison_dat%>%
ggplot(aes(x=guesses,y=ratings,colour=ideophone,label=identifier))+geom_point()+theme_classic()+geom_smooth(method="lm")->plot
plot
# If you want to see which words are which dots -- ggplotly will let you hover over them
#ggplotly(plot)
comparison_dat%>%
select(-score)%>%
pivot_wider(names_from = "method",values_from="z_score")->comparison_dat
comparison_dat%>%
select(-score)%>%
pivot_wider(names_from = "method",values_from="z_score")->comparison_dat
comparison_dat%>%
mutate(word_type=ifelse(ideophone=="y","ideophone","prosaic"))%>%
ggplot(aes(x=guesses,y=ratings,colour=word_type,label=identifier))+geom_point()+theme_classic()+geom_smooth(method="lm")+labs(colour="Word type")->plot
plot
comparison_dat%>%
mutate(word_type=ifelse(ideophone=="y","ideophone","prosaic"))%>%
ggplot(aes(x=guesses,y=ratings,colour=word_type,label=identifier))+geom_point()+theme_classic()+geom_smooth(method="lm")+labs(colour="Lexical stratum")->plot
plot
View(comparison_dat)
comparison_dat%>%
mutate(stratum=ifelse(ideophone=="y","ideophone","prosaic"))->comparison_dat
m1 <- lm(data=comparison_dat,guesses~ratings*stratum)
tab_model(m1,show.ci = FALSE,show.se = TRUE,show.stat = TRUE, dv.labels = c("Guesses"),  CSS = list(
css.table = 'width: 90%;'
))
ggpredict(m1,c("ratings","stratum"))%>%plot()
m3 <- lm(data=comparison_dat,ratings~guesses*stratum)
tab_model(m3,show.ci = FALSE,show.se = TRUE,show.stat = TRUE, dv.labels = c("Ratings"),  CSS = list(
css.table = 'width: 90%;'
))
tab_model(m1,show.ci = FALSE,show.se = TRUE,show.stat = TRUE, dv.labels = c("Guesses"),  CSS = list(
css.table = 'width: 90%;'
))
tab_model(m3,show.ci = FALSE,show.se = TRUE,show.stat = TRUE, dv.labels = c("Ratings"),  CSS = list(
css.table = 'width: 90%;'
))
ggpredict(m3,c("guesses","stratum"))%>%plot()
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip() +ylim(0,0.6)+theme_classic()+labs(y="Correlation (r)",x="")->plot
load("C:/Users/bonmc643/IconicityMeasuresJaponic/paper_cache/docx/run bootstrap_96e334f450d4163f8f9d650f36bcb7b7.RData")
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +
coord_flip() +ylim(0,0.6)+theme_classic()+labs(y="Correlation (r)",x="")->plot
load("C:/Users/bonmc643/IconicityMeasuresJaponic/paper_cache/html/bootstrap function_0fd3a00088e4f6c8255c7571b5f98d1d.RData")
load("C:/Users/bonmc643/IconicityMeasuresJaponic/paper_cache/html/run bootstrap_26123b8090905d32cd82a3410f1d36d6.RData")
load("C:/Users/bonmc643/IconicityMeasuresJaponic/paper_cache/docx/run bootstrap_96e334f450d4163f8f9d650f36bcb7b7.rdb")
# my ratings from English people
ratings%>%
group_by(identifier)%>%
mutate(mean_rating=mean(rating))%>%
select(iconicityM=mean_rating,rating,prolificID)%>%
mutate(task="current study")%>%
mutate(form=str_split(identifier,"_")[[1]][1])%>%
left_join(info,by="form")%>%
ungroup()%>%
unique()%>%
select(-form,-identifier,-prolificID)->ratingdat
# Thompson's ratings from Japanese people
thompson%>%
select(iconicityM,rating,task,ideophone)->thompson
datasets <- list(ratingdat,thompson)
# code from Motamedi et al. 2019
R <- 5000
# Bootstrap function, calculating the correlation coefficient for each bootstrapped sample
bootCor <- function(data, i){
d <- data[i,]
rDf <- correlate(d %>% select(-task))
return(rDf[[2,2]])
}
# Split the data by halves of the rating scale, apply the above bootstrap function, and extract confidence intervals
corRatings <- function(data){
# Separate the data into ideophones and non-ideophones
negData <- data %>% filter(ideophone=="n")%>%select(-ideophone)
posData <- data %>% filter(ideophone=="y")%>%select(-ideophone)
#negData <- data %>% filter(rating<0)
#posData <- data %>% filter(rating>0)
# Bootstrap the correlation between each negative rating, and the by-item average
negBoot <- boot(negData, bootCor, R=R)
negCI <- boot.ci(negBoot, type="bca")
rNeg <- negBoot$t0
lowerNeg <- negCI$bca[[4]]
upperNeg <- negCI$bca[[5]]
# Bootstrap the correlation between each positive rating, and the by-item average
posBoot <- boot(posData, bootCor, R=R)
rPos <- posBoot$t0
posCI <- boot.ci(posBoot, type="bca")
lowerPos <- posCI$bca[[4]]
upperPos <- posCI$bca[[5]]
return(list(list(lowerPos,upperPos,rPos), list(lowerNeg,upperNeg,rNeg)))
}
# Initialize an empty dataframe to store values
cis <- data.frame(name=character(), sign=character(), r=numeric(), lower=numeric(), upper=numeric(), stringsAsFactors=FALSE)
# Iterate over datasets
for(dataset in datasets) {
# Track the name of the current dataset
name <- dataset$task[1]
# For each dataset, apply the function corRatings described above
c(c(posLower, posUpper, posR), c(negLower, negUpper, negR)) %<-% corRatings(dataset)
# Append the results to the dataframe
cis[nrow(cis) + 1,] = list(name, 'ideophone', posR, posLower, posUpper)
cis[nrow(cis) + 1,] = list(name, 'prosaic', negR, negLower, negUpper)
}
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +ylim(0,0.6)+theme_classic()+labs(y="Correlation (r)",x="")->plot
plot
cis %>%
ggplot(aes(x=name,
y=r,
ymin=lower,
ymax=upper,
color=sign)) +
geom_point(position=position_dodge(0.1)) +
geom_errorbar(position=position_dodge(0.1),
width=0.1) +ylim(0,0.6)+theme_classic()+labs(y="Correlation (r)",x="",color="word type")->plot
plot
plot
plot
knitr::include_graphics("images/bootstrap.png")
graph
library(tidyverse)
library(kableExtra)
library(bookdown)
library(report)
library(lmerTest)
library(plotly)
library(corrr)
library(boot)
library(zeallot)
library(pander)
library(sjPlot)
library(ggeffects)
library(gridExtra)
library(gghalves)
knitr::opts_chunk$set(echo = FALSE,warning=FALSE,message = FALSE)
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))->plot
plot
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))+theme(aspect.ratio = 1)
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))+theme(aspect.ratio = 1)
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))+theme(aspect.ratio = 2)
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))+theme(aspect.ratio = 0.5)
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))+theme(aspect.ratio = 0.5)->plot
plot
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))+ coord_fixed(ratio = 0.2)
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))+ coord_fixed(ratio = 0.2)
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))+ coord_fixed(ratio = 0.5)
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))+ coord_fixed(ratio = 0.1)
graph%>%
mutate(domain=fct_relevel(domain,c("sound","action","shape & size","appearance","texture","temperature","taste","pain","bodily feeling","emotion")))%>%
ggplot(aes(x=domain,y=n,fill=stratum))+geom_col()+theme_minimal()+labs(x="Semantic domain",fill="Lexical stratum")+theme(axis.text.x = element_text(angle=15))+scale_fill_manual(values=c("darkgrey","black"))+ coord_fixed(ratio = 0.1)->plot
plot
View(ratingres)
